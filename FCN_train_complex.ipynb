{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=480\n",
    "img_width=640\n",
    "#Network Parameters\n",
    "n_input=img_height*img_width*3\n",
    "learning_rate=1e-8\n",
    "training_iters=10000\n",
    "batch_size=3\n",
    "display_step=8\n",
    "dropout=0.8\n",
    "epoch=3\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "#tf graph input\n",
    "xx=tf.placeholder(tf.float32,[1,img_height*img_width*3])\n",
    "yy=tf.placeholder(tf.float32,[None,img_height,img_width,16])\n",
    "keep_prob=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(img,w,b):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img,w,strides=[1,1,1,1],padding='SAME'),b))\n",
    "def max_pool(img,k):\n",
    "    return tf.nn.max_pool(img,ksize=[1,k,k,1],strides=[1,k,k,1],padding='SAME')\n",
    "def conv2d_transpose(img,w,b,outputShape):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d_transpose(img,w,output_shape=outputShape,strides=[1,1,1,1],padding='SAME'),b))\n",
    "def conv2d_output(img,w,b):\n",
    "    return tf.nn.sigmoid(tf.nn.bias_add(tf.nn.conv2d(img,w,strides=[1,1,1,1],padding='SAME'),b))\n",
    "def bottleneck(img,w1,w2):\n",
    "    tmp_bn_1=tf.nn.relu(tf.nn.conv2d(img,w1,strides=[1,1,1,1],padding='SAME'))\n",
    "    tmp_bn_2=tf.nn.conv2d(tmp_bn_1,w2,strides=[1,1,1,1],padding='SAME')\n",
    "    return (img+tmp_bn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc1=tf.Variable(tf.random_normal([7,7,3,64]),name=\"wc1\")\n",
    "bc1=tf.Variable(tf.random_normal([64]),name=\"bc1\")\n",
    "\n",
    "wc2=tf.Variable(tf.random_normal([5,5,256,64]),name=\"wc2\")\n",
    "bc2=tf.Variable(tf.random_normal([64]),name=\"bc2\")\n",
    "\n",
    "wc3=tf.Variable(tf.random_normal([5,5,64,16]),name=\"wc3\")\n",
    "bc3=tf.Variable(tf.random_normal([16]),name=\"bc3\")\n",
    "\n",
    "wc4=tf.Variable(tf.random_normal([1,1,16,16]),name=\"wc4\")\n",
    "bc4=tf.Variable(tf.random_normal([16]),name=\"bc4\")\n",
    "#bottleneck\n",
    "w_bn_1=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_1\")\n",
    "w_bn_2=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_2\")\n",
    "\n",
    "w_bn_3=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_3\")\n",
    "w_bn_4=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_4\")\n",
    "\n",
    "w_bn_5=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_5\")\n",
    "w_bn_6=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_6\")\n",
    "\n",
    "w_bn_7=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_7\")\n",
    "w_bn_8=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_8\")\n",
    "\n",
    "w_bn_9=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_9\")\n",
    "w_bn_10=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_10\")\n",
    "\n",
    "#branches\n",
    "w_br_1=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_1\")\n",
    "w_br_2=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_2\")\n",
    "\n",
    "w_br_3=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_3\")\n",
    "w_br_4=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_4\")\n",
    "\n",
    "w_br_5=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_5\")\n",
    "w_br_6=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_6\")\n",
    "\n",
    "w_br_7=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_7\")\n",
    "w_br_8=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_8\")\n",
    "\n",
    "#deconcolution\n",
    "w_dc_1=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_1\")\n",
    "b_dc_1=tf.Variable(tf.random_normal([64]),name=\"b_dc_1\")\n",
    "\n",
    "w_dc_2=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_2\")\n",
    "b_dc_2=tf.Variable(tf.random_normal([64]),name=\"b_dc_2\")\n",
    "\n",
    "w_dc_3=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_3\")\n",
    "b_dc_3=tf.Variable(tf.random_normal([64]),name=\"b_dc_3\")\n",
    "\n",
    "w_dc_4=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_4\")\n",
    "b_dc_4=tf.Variable(tf.random_normal([64]),name=\"b_dc_4\")\n",
    "\n",
    "w_dc_5=tf.Variable(tf.random_normal([2,2,256,64]),name=\"w_dc_5\")\n",
    "b_dc_5=tf.Variable(tf.random_normal([256]),name=\"b_dc_5\")\n",
    "\n",
    "w_dc_6=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_6\")\n",
    "b_dc_6=tf.Variable(tf.random_normal([64]),name=\"b_dc_6\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X=tf.reshape(xx,shape=[-1,img_height,img_width,3])\n",
    "conv1=conv2d(_X,wc1,bc1)\n",
    "conv1_pooling=max_pool(conv1,k=2)\n",
    "conv1_pooling=tf.nn.dropout(conv1_pooling,keep_prob)\n",
    "\n",
    "\n",
    "bn1=bottleneck(conv1_pooling,w_bn_1,w_bn_2)\n",
    "bn1=tf.nn.dropout(bn1,keep_prob)\n",
    "\n",
    "bn1_pooling=max_pool(bn1,k=2)\n",
    "bn2=bottleneck(bn1_pooling,w_bn_3,w_bn_4)\n",
    "bn2=tf.nn.dropout(bn2,keep_prob)\n",
    "\n",
    "bn2_pooling=max_pool(bn2,k=2)\n",
    "bn3=bottleneck(bn2_pooling,w_bn_5,w_bn_6)\n",
    "bn3=tf.nn.dropout(bn3,keep_prob)\n",
    "\n",
    "bn3_pooling=max_pool(bn3,k=2)\n",
    "bn4=bottleneck(bn3_pooling,w_bn_7,w_bn_8)\n",
    "bn4=tf.nn.dropout(bn4,keep_prob)\n",
    "\n",
    "bn4_pooling=max_pool(bn4,k=2)\n",
    "bn5=bottleneck(bn4_pooling,w_bn_9,w_bn_10)\n",
    "bn5=tf.nn.dropout(bn5,keep_prob)\n",
    "\n",
    "bran1=bottleneck(bn5,w_br_1,w_br_2)\n",
    "\n",
    "tmpShape=bran1.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "dc1=conv2d_transpose(bn5,w_dc_1,b_dc_1,outputShape=tmpShape)\n",
    "\n",
    "add1=dc1+bran1\n",
    "add1=tf.nn.dropout(add1,keep_prob)\n",
    "\n",
    "\n",
    "bran2=bottleneck(bn4,w_br_3,w_br_4)\n",
    "\n",
    "add1=tf.image.resize_bilinear(add1,bn4.get_shape().as_list()[1:3])\n",
    "tmpShape=bran2.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "dc2=conv2d_transpose(add1,w_dc_2,b_dc_2,outputShape=tmpShape)\n",
    "\n",
    "add2=dc2+bran2\n",
    "add2=tf.nn.dropout(add2,keep_prob)\n",
    "\n",
    "\n",
    "bran3=bottleneck(bn3,w_br_5,w_br_6)\n",
    "\n",
    "add2=tf.image.resize_bilinear(add2,bn3.get_shape().as_list()[1:3])\n",
    "tmpShape=bran3.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "dc3=conv2d_transpose(add2,w_dc_3,b_dc_3,outputShape=tmpShape)\n",
    "\n",
    "add3=dc3+bran3\n",
    "add3=tf.nn.dropout(add3,keep_prob)\n",
    "\n",
    "\n",
    "bran4=bottleneck(bn2,w_br_7,w_br_8)\n",
    "\n",
    "add3=tf.image.resize_bilinear(add3,bn2.get_shape().as_list()[1:3])\n",
    "tmpShape=bran4.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "dc4=conv2d_transpose(add3,w_dc_4,b_dc_4,outputShape=tmpShape)\n",
    "\n",
    "add4=dc4+bran4\n",
    "add4=tf.nn.dropout(add4,keep_prob)\n",
    "\n",
    "\n",
    "add4=tf.image.resize_bilinear(add4,bn1.get_shape().as_list()[1:3])\n",
    "tmpShape=bn1.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "tmpShape[3]=256\n",
    "dc5=conv2d_transpose(add4,w_dc_5,b_dc_5,outputShape=tmpShape)\n",
    "\n",
    "conv2=conv2d(dc5,wc2,bc2)\n",
    "conv2=tf.nn.dropout(conv2,keep_prob)\n",
    "\n",
    "conv2=tf.image.resize_bilinear(conv2,_X.get_shape().as_list()[1:3])\n",
    "tmpShape=_X.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "tmpShape[3]=64\n",
    "dc6=conv2d_transpose(conv2,w_dc_6,b_dc_6,outputShape=tmpShape)\n",
    "\n",
    "conv3=conv2d(dc6,wc3,bc3)\n",
    "conv3=tf.nn.dropout(conv3,keep_prob)\n",
    "\n",
    "conv4=conv2d(conv3,wc4,bc4)\n",
    "\n",
    "cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=conv_t2,labels=y))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver({\"wc1\":wc1,\"bc1\":bc1,\"wc2\":wc2,\"bc2\":bc2,\"wc3\":wc3,\"bc3\":bc3,\"wc4\":wc4,\"bc4\":bc4,\n",
    "                        \"w_bn_1\":w_bn_1,\"w_bn_2\":w_bn_2,\"w_bn_3\":w_bn_3,\"w_bn_4\":w_bn_4,\"w_bn_5\":w_bn_5,\"w_bn_6\":w_bn_6,\n",
    "                        \"w_bn_7\":w_bn_7,\"w_bn_8\":w_bn_8,\"w_bn_9\":w_bn_9,\"w_bn_10\":w_bn_10,\n",
    "                        \"w_br_1\":w_br_1,\"w_br_2\":w_br_2,\"w_br_3\":w_br_3,\"w_br_4\":w_br_4,\"w_br_5\":w_br_5,\"w_br_6\":w_br_6,\n",
    "                        \"w_br_7\":w_br_1,\"w_br_8\":w_br_8,\n",
    "                        \"w_dc_1\":w_dc_1,\"w_dc_2\":w_dc_2,\"w_dc_3\":w_dc_3,\"w_dc_4\":w_dc_4,\"w_dc_5\":w_dc_5,\"w_dc_6\":w_dc_6\n",
    "                       })\n",
    "init=tf.global_variables_initializer()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 480, 640, 16)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()\n",
    "    #saver.restore(sess,\"model/model.ckpt\")\n",
    "    for i in range(0,epoch):\n",
    "        print(\"epoch:\"+str(i)+\"       !!!!!!!!!!!!\")\n",
    "        step=0\n",
    "        now_at=0\n",
    "        while step*batch_size<training_iters:\n",
    "            X,Y=input_data.next_batch(\n",
    "                    img_dir_path='mpii_human_pose_v1\\\\output_images\\\\',\n",
    "                    index_path='train_data\\\\new_data.json',\n",
    "                    img_height=img_height,img_width=img_width,\n",
    "                    batch_size=batch_size,now_at=now_at)\n",
    "            sess.run(optimizer,feed_dict = {x:xx,y:yy,keep_prob:dropout})\n",
    "            loss=sess.run(cost,feed_dict = {x:xx,y:yy,keep_prob:1.})\n",
    "            if step%display_step==0:\n",
    "                print(\"Iter \"+str(step*batch_size)+\", Minibatch Loss=\"+\"{:.6f}\".format(loss))\n",
    "            step+=1\n",
    "            now_at+=batch_size\n",
    "    save_path = saver.save(sess, \"model/model_complex.ckpt\")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
