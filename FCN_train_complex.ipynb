{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height=480\n",
    "img_width=360\n",
    "#Network Parameters\n",
    "n_input=img_height*img_width*3\n",
    "learning_rate=5e-19\n",
    "training_iters=10000\n",
    "batch_size=1\n",
    "display_step=1\n",
    "dropout=0.8\n",
    "epoch=1\n",
    "tf.reset_default_graph()\n",
    "#tf graph input\n",
    "xx=tf.placeholder(tf.float32,[None,img_height,img_width,3])\n",
    "yy=tf.placeholder(tf.float32,[None,img_height,img_width,16])\n",
    "keep_prob=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(img,w,b):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(img,w,strides=[1,1,1,1],padding='SAME'),b))\n",
    "def max_pool(img,k):\n",
    "    return tf.nn.max_pool(img,ksize=[1,k,k,1],strides=[1,k,k,1],padding='SAME')\n",
    "def conv2d_transpose(img,w,b,outputShape):\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d_transpose(img,w,output_shape=outputShape,strides=[1,1,1,1],padding='SAME'),b))\n",
    "def conv2d_output(img,w,b):\n",
    "    return tf.nn.sigmoid(tf.nn.bias_add(tf.nn.conv2d(img,w,strides=[1,1,1,1],padding='SAME'),b))\n",
    "def bottleneck(img,w1,w2):\n",
    "    tmp_bn_1=tf.nn.relu(tf.nn.conv2d(img,w1,strides=[1,1,1,1],padding='SAME'))\n",
    "    tmp_bn_2=tf.nn.conv2d(tmp_bn_1,w2,strides=[1,1,1,1],padding='SAME')\n",
    "    return (img+tmp_bn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc1=tf.Variable(tf.random_normal([7,7,3,64]),name=\"wc1\")\n",
    "bc1=tf.Variable(tf.random_normal([64]),name=\"bc1\")\n",
    "\n",
    "wc2=tf.Variable(tf.random_normal([5,5,256,64]),name=\"wc2\")\n",
    "bc2=tf.Variable(tf.random_normal([64]),name=\"bc2\")\n",
    "\n",
    "wc3=tf.Variable(tf.random_normal([5,5,64,16]),name=\"wc3\")\n",
    "bc3=tf.Variable(tf.random_normal([16]),name=\"bc3\")\n",
    "\n",
    "wc4=tf.Variable(tf.random_normal([1,1,16,16]),name=\"wc4\")\n",
    "bc4=tf.Variable(tf.random_normal([16]),name=\"bc4\")\n",
    "#bottleneck\n",
    "w_bn_1=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_1\")\n",
    "w_bn_2=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_2\")\n",
    "\n",
    "w_bn_3=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_3\")\n",
    "w_bn_4=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_4\")\n",
    "\n",
    "w_bn_5=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_5\")\n",
    "w_bn_6=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_6\")\n",
    "\n",
    "w_bn_7=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_7\")\n",
    "w_bn_8=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_8\")\n",
    "\n",
    "w_bn_9=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_9\")\n",
    "w_bn_10=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_bn_10\")\n",
    "\n",
    "#branches\n",
    "w_br_1=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_1\")\n",
    "w_br_2=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_2\")\n",
    "\n",
    "w_br_3=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_3\")\n",
    "w_br_4=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_4\")\n",
    "\n",
    "w_br_5=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_5\")\n",
    "w_br_6=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_6\")\n",
    "\n",
    "w_br_7=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_7\")\n",
    "w_br_8=tf.Variable(tf.random_normal([5,5,64,64]),name=\"w_br_8\")\n",
    "\n",
    "#deconcolution\n",
    "w_dc_1=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_1\")\n",
    "b_dc_1=tf.Variable(tf.random_normal([64]),name=\"b_dc_1\")\n",
    "\n",
    "w_dc_2=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_2\")\n",
    "b_dc_2=tf.Variable(tf.random_normal([64]),name=\"b_dc_2\")\n",
    "\n",
    "w_dc_3=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_3\")\n",
    "b_dc_3=tf.Variable(tf.random_normal([64]),name=\"b_dc_3\")\n",
    "\n",
    "w_dc_4=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_4\")\n",
    "b_dc_4=tf.Variable(tf.random_normal([64]),name=\"b_dc_4\")\n",
    "\n",
    "w_dc_5=tf.Variable(tf.random_normal([2,2,256,64]),name=\"w_dc_5\")\n",
    "b_dc_5=tf.Variable(tf.random_normal([256]),name=\"b_dc_5\")\n",
    "\n",
    "w_dc_6=tf.Variable(tf.random_normal([2,2,64,64]),name=\"w_dc_6\")\n",
    "b_dc_6=tf.Variable(tf.random_normal([64]),name=\"b_dc_6\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1=conv2d(xx,wc1,bc1)\n",
    "conv1_pooling=max_pool(conv1,k=2)\n",
    "conv1_pooling=tf.nn.dropout(conv1_pooling,keep_prob)\n",
    "\n",
    "\n",
    "bn1=bottleneck(conv1_pooling,w_bn_1,w_bn_2)\n",
    "bn1=tf.nn.dropout(bn1,keep_prob)\n",
    "\n",
    "bn1_pooling=max_pool(bn1,k=2)\n",
    "bn2=bottleneck(bn1_pooling,w_bn_3,w_bn_4)\n",
    "bn2=tf.nn.dropout(bn2,keep_prob)\n",
    "\n",
    "bn2_pooling=max_pool(bn2,k=2)\n",
    "bn3=bottleneck(bn2_pooling,w_bn_5,w_bn_6)\n",
    "bn3=tf.nn.dropout(bn3,keep_prob)\n",
    "\n",
    "bn3_pooling=max_pool(bn3,k=2)\n",
    "bn4=bottleneck(bn3_pooling,w_bn_7,w_bn_8)\n",
    "bn4=tf.nn.dropout(bn4,keep_prob)\n",
    "\n",
    "bn4_pooling=max_pool(bn4,k=2)\n",
    "bn5=bottleneck(bn4_pooling,w_bn_9,w_bn_10)\n",
    "bn5=tf.nn.dropout(bn5,keep_prob)\n",
    "\n",
    "bran1=bottleneck(bn5,w_br_1,w_br_2)\n",
    "\n",
    "tmpShape=bran1.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "dc1=conv2d_transpose(bn5,w_dc_1,b_dc_1,outputShape=tmpShape)\n",
    "\n",
    "add1=dc1+bran1\n",
    "add1=tf.nn.dropout(add1,keep_prob)\n",
    "\n",
    "\n",
    "bran2=bottleneck(bn4,w_br_3,w_br_4)\n",
    "\n",
    "add1=tf.image.resize_bilinear(add1,bn4.get_shape().as_list()[1:3])\n",
    "tmpShape=bran2.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "dc2=conv2d_transpose(add1,w_dc_2,b_dc_2,outputShape=tmpShape)\n",
    "\n",
    "add2=dc2+bran2\n",
    "add2=tf.nn.dropout(add2,keep_prob)\n",
    "\n",
    "\n",
    "bran3=bottleneck(bn3,w_br_5,w_br_6)\n",
    "\n",
    "add2=tf.image.resize_bilinear(add2,bn3.get_shape().as_list()[1:3])\n",
    "tmpShape=bran3.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "dc3=conv2d_transpose(add2,w_dc_3,b_dc_3,outputShape=tmpShape)\n",
    "\n",
    "add3=dc3+bran3\n",
    "add3=tf.nn.dropout(add3,keep_prob)\n",
    "\n",
    "\n",
    "bran4=bottleneck(bn2,w_br_7,w_br_8)\n",
    "\n",
    "add3=tf.image.resize_bilinear(add3,bn2.get_shape().as_list()[1:3])\n",
    "tmpShape=bran4.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "dc4=conv2d_transpose(add3,w_dc_4,b_dc_4,outputShape=tmpShape)\n",
    "\n",
    "add4=dc4+bran4\n",
    "add4=tf.nn.dropout(add4,keep_prob)\n",
    "\n",
    "\n",
    "add4=tf.image.resize_bilinear(add4,bn1.get_shape().as_list()[1:3])\n",
    "tmpShape=bn1.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "tmpShape[3]=256\n",
    "dc5=conv2d_transpose(add4,w_dc_5,b_dc_5,outputShape=tmpShape)\n",
    "\n",
    "conv2=conv2d(dc5,wc2,bc2)\n",
    "conv2=tf.nn.dropout(conv2,keep_prob)\n",
    "\n",
    "conv2=tf.image.resize_bilinear(conv2,xx.get_shape().as_list()[1:3])\n",
    "tmpShape=xx.get_shape().as_list()\n",
    "tmpShape[0]=batch_size\n",
    "tmpShape[3]=64\n",
    "dc6=conv2d_transpose(conv2,w_dc_6,b_dc_6,outputShape=tmpShape)\n",
    "\n",
    "conv3=conv2d(dc6,wc3,bc3)\n",
    "conv3=tf.nn.dropout(conv3,keep_prob)\n",
    "\n",
    "conv4=conv2d(conv3,wc4,bc4)\n",
    "\n",
    "cost=tf.reduce_mean(tf.square(tf.subtract(conv4,yy)))\n",
    "#cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=conv4,labels=yy))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver({\"wc1\":wc1,\"bc1\":bc1,\"wc2\":wc2,\"bc2\":bc2,\"wc3\":wc3,\"bc3\":bc3,\"wc4\":wc4,\"bc4\":bc4,\n",
    "                        \"w_bn_1\":w_bn_1,\"w_bn_2\":w_bn_2,\"w_bn_3\":w_bn_3,\"w_bn_4\":w_bn_4,\"w_bn_5\":w_bn_5,\"w_bn_6\":w_bn_6,\n",
    "                        \"w_bn_7\":w_bn_7,\"w_bn_8\":w_bn_8,\"w_bn_9\":w_bn_9,\"w_bn_10\":w_bn_10,\n",
    "                        \"w_br_1\":w_br_1,\"w_br_2\":w_br_2,\"w_br_3\":w_br_3,\"w_br_4\":w_br_4,\"w_br_5\":w_br_5,\"w_br_6\":w_br_6,\n",
    "                        \"w_br_7\":w_br_7,\"w_br_8\":w_br_8,\n",
    "                        \"w_dc_1\":w_dc_1,\"w_dc_2\":w_dc_2,\"w_dc_3\":w_dc_3,\"w_dc_4\":w_dc_4,\"w_dc_5\":w_dc_5,\"w_dc_6\":w_dc_6\n",
    "                       })\n",
    "init=tf.global_variables_initializer()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0       !!!!!!!!!!!!\n",
      "Iter 0, Minibatch Loss=inf\n",
      "Iter 1, Minibatch Loss=0.000868\n",
      "Iter 2, Minibatch Loss=0.000868\n",
      "Iter 3, Minibatch Loss=0.000868\n",
      "Iter 4, Minibatch Loss=0.000868\n",
      "Iter 5, Minibatch Loss=0.000868\n",
      "Iter 6, Minibatch Loss=0.000868\n",
      "Iter 7, Minibatch Loss=0.000868\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1ae9ccb032e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mimg_height\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     batch_size=batch_size,now_at=now_at)\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[1;31m#fp=open(\"graph.txt\",'w')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m#for each_line in output[2][0]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gatl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gatl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gatl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gatl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gatl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gatl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()\n",
    "    for i in range(0,epoch):\n",
    "        print(\"epoch:\"+str(i)+\"       !!!!!!!!!!!!\")\n",
    "        step=0\n",
    "        now_at=0\n",
    "        while step*batch_size<training_iters:\n",
    "            X=input_data.x_next_batch(\n",
    "                    img_dir_path='mpii_human_pose_v1\\\\output_images360x480\\\\',\n",
    "                    index_path='train_data\\\\new_data.json',\n",
    "                    img_height=img_height,img_width=img_width,\n",
    "                    batch_size=batch_size,now_at=now_at)\n",
    "            Y=input_data.y_next_batch(\n",
    "                    img_dir_path='mpii_human_pose_v1\\\\output_images360x480\\\\',\n",
    "                    index_path='train_data\\\\new_data.json',\n",
    "                    img_height=img_height,img_width=img_width,\n",
    "                    batch_size=batch_size,now_at=now_at)\n",
    "            output=sess.run([optimizer,cost],feed_dict = {xx:X,yy:Y,keep_prob:dropout})\n",
    "            #fp=open(\"graph.txt\",'w')\n",
    "            #for each_line in output[2][0]:\n",
    "             #   for each_ele in each_line:\n",
    "             #       fp.write(str(each_ele[0])+\" \")\n",
    "             #   fp.write(\"\\n\")\n",
    "            #fp.close()\n",
    "            #break\n",
    "            if step%display_step==0:\n",
    "                #loss=sess.run(cost,feed_dict = {xx:X,yy:Y,keep_prob:1.})\n",
    "                #loss=cost.eval(feed_dict = {xx:X,yy:Y,keep_prob:1.})\n",
    "                print(\"Iter \"+str(step*batch_size)+\", Minibatch Loss=\"+\"{:.6f}\".format(output[1]))\n",
    "            step+=1\n",
    "            now_at+=batch_size\n",
    "        #save_path = saver.save(sess, \"model/model_complex.ckpt\")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
